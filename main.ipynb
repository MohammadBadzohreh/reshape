{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorly-torch in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly-torch) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly-torch) (1.10.1)\n",
      "Requirement already satisfied: nose in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly-torch) (1.3.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorly in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\mohammad badzohreh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Necessary Packages\n",
    "!pip install tensorly-torch\n",
    "!pip install tensorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tltorch # TCL and TRL\n",
    "import tensorly as tl # Tensor operation\n",
    "import torch   #  Neural Network\n",
    "from torch import nn # Neural Network\n",
    "from torch.autograd import Variable # Tensor input\n",
    "import torch.optim as optim # Optimization\n",
    "from torchvision import datasets, transforms # Datasets and transoforms\n",
    "import torchvision # Data Loader\n",
    "import torch.nn.functional as F # Activation Functions\n",
    "\n",
    "import numpy as np # Numerical operations\n",
    "import itertools # Generate indices\n",
    "\n",
    "import matplotlib.pyplot as plt # Generate plots\n",
    "import pandas as pd # Save the result as a sheet\n",
    "\n",
    "import time # execuation time\n",
    "\n",
    "import matplotlib.pyplot as plt # to plot and display the images\n",
    "\n",
    "# from skimage import data # To load only one image\n",
    "\n",
    "from reshape.reshape import MyReshape\n",
    "from reshape.reshape import MyReshape2\n",
    "from reshape.reshape import MyReshape3\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset # To add choose only a subset of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainset_subset = Subset(trainset, range(0, 50))\n",
    "trainloader = DataLoader(trainset_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "additional_trainset_subset = Subset(trainset, range(50, 60000))\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "combined_testset = ConcatDataset([testset, additional_trainset_subset])\n",
    "\n",
    "testloader = DataLoader(combined_testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Image batch shape: torch.Size([4, 1, 28, 28])\n",
      "Label batch shape: torch.Size([4])\n",
      "\n",
      "Testing set:\n",
      "Image batch shape: torch.Size([4, 1, 28, 28])\n",
      "Label batch shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the data in training set\n",
    "for images, labels in trainloader:\n",
    "    print(\"Training set:\")\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    break  # Print only the first batch\n",
    "\n",
    "# Get the shape of the data in testing set\n",
    "for images, labels in testloader:\n",
    "    print(\"\\nTesting set:\")\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    break  # Print only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        self.tcl = tltorch.TCL(input_shape=[2, 2, 2, 25, 2, 2], rank=[1, 1, 1, 13, 2, 2])\n",
    "        self.trl = tltorch.TRL(input_shape=[13, 2, 2], output_shape=[10], factorization='Tucker', rank=[10, 3, 3, 10])\n",
    "        self.device = device\n",
    "        self.reshaper = MyReshape(device)\n",
    "\n",
    "    def forward(self, x, map_type=1):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        \n",
    "        x = self.reshaper(x, map_type)\n",
    "        \n",
    "        x = F.relu(self.tcl(x)).squeeze()\n",
    "        x = self.trl(x)\n",
    "        return F.log_softmax(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        self.tcl = tltorch.TCL(input_shape=[2, 2, 2, 25, 2, 2], rank=[1, 1, 1, 13, 2, 2])\n",
    "        self.trl = tltorch.TRL(input_shape=[13, 2, 2], output_shape=[10], factorization='Tucker', rank=[10, 3, 3, 10])\n",
    "        self.device = device\n",
    "        self.reshaper = MyReshape2(device)\n",
    "\n",
    "    def forward(self, x, map_type=1):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        \n",
    "        x = self.reshaper(x, map_type)\n",
    "        \n",
    "        x = F.relu(self.tcl(x)).squeeze()\n",
    "        x = self.trl(x)\n",
    "        return F.log_softmax(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        self.tcl = tltorch.TCL(input_shape=[2, 2, 2, 25, 2, 2], rank=[1, 1, 1, 13, 2, 2])\n",
    "        self.trl = tltorch.TRL(input_shape=[13, 2, 2], output_shape=[10], factorization='Tucker', rank=[10, 3, 3, 10])\n",
    "        self.device = device\n",
    "        self.reshaper = MyReshape3(device)\n",
    "\n",
    "    def forward(self, x, map_type=1):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        \n",
    "        x = self.reshaper(x, map_type)\n",
    "        \n",
    "        x = F.relu(self.tcl(x)).squeeze()\n",
    "        x = self.trl(x)\n",
    "        return F.log_softmax(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.219562\n",
      "Train Epoch: 0 [20/50 (38%)]\tLoss: 2.272348\n",
      "Train Epoch: 0 [40/50 (77%)]\tLoss: 2.307836\n",
      "Train Epoch: 1 [0/50 (0%)]\tLoss: 2.161656\n",
      "Train Epoch: 1 [20/50 (38%)]\tLoss: 2.204363\n",
      "Train Epoch: 1 [40/50 (77%)]\tLoss: 2.191953\n",
      "Train Epoch: 2 [0/50 (0%)]\tLoss: 2.024172\n",
      "Train Epoch: 2 [20/50 (38%)]\tLoss: 2.269480\n",
      "Train Epoch: 2 [40/50 (77%)]\tLoss: 1.661605\n",
      "Training for all 3 epochs completed in: 9.21672773361206 seconds\n",
      "end train\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "n_epoch = 3\n",
    "model = Net(device='cuda').to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_1_Train = []\n",
    "loss_1_Test = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss))\n",
    "    \n",
    "    avg_loss = total_loss / len(trainloader)\n",
    "    loss_1_Train.append(avg_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"start train\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train(epoch)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training for all {n_epoch} epochs completed in: {end_time - start_time} seconds\")\n",
    "\n",
    "print(\"end train\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in testloader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += criterion(output, target).item()\n",
    "#             pred = output.data.max(1, keepdim=True)[1]\n",
    "#             correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#     avg_test_loss = test_loss / len(testloader)\n",
    "#     loss_1_Test.append(avg_test_loss)\n",
    "#     print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         avg_test_loss, correct, len(testloader.dataset),\n",
    "#         100. * correct / len(testloader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# st = time.time()\n",
    "# for epoch in range(1, n_epoch + 1):\n",
    "#     train(epoch)\n",
    "#     test()\n",
    "\n",
    "# elapsed_time = time.time() - st\n",
    "# print('Execution time:', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.292078\n",
      "Train Epoch: 0 [20/50 (38%)]\tLoss: 2.319593\n",
      "Train Epoch: 0 [40/50 (77%)]\tLoss: 2.296949\n",
      "Train Epoch: 1 [0/50 (0%)]\tLoss: 2.264895\n",
      "Train Epoch: 1 [20/50 (38%)]\tLoss: 2.223021\n",
      "Train Epoch: 1 [40/50 (77%)]\tLoss: 2.359742\n",
      "Train Epoch: 2 [0/50 (0%)]\tLoss: 2.296491\n",
      "Train Epoch: 2 [20/50 (38%)]\tLoss: 2.269852\n",
      "Train Epoch: 2 [40/50 (77%)]\tLoss: 2.251085\n",
      "Training for all 3 epochs completed in: 8.163865089416504 seconds\n",
      "end train\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "n_epoch = 3\n",
    "model = Net2(device='cuda').to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_1_Train = []\n",
    "loss_1_Test = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss))\n",
    "    \n",
    "    avg_loss = total_loss / len(trainloader)\n",
    "    loss_1_Train.append(avg_loss)\n",
    "\n",
    "print(\"start train\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train(epoch)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training for all {n_epoch} epochs completed in: {end_time - start_time} seconds\")\n",
    "\n",
    "print(\"end train\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in testloader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += criterion(output, target).item()\n",
    "#             pred = output.data.max(1, keepdim=True)[1]\n",
    "#             correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#     avg_test_loss = test_loss / len(testloader)\n",
    "#     loss_1_Test.append(avg_test_loss)\n",
    "#     print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         avg_test_loss, correct, len(testloader.dataset),\n",
    "#         100. * correct / len(testloader.dataset)))\n",
    "\n",
    "# st = time.time()\n",
    "# for epoch in range(1, n_epoch + 1):\n",
    "#     train(epoch)\n",
    "#     test()\n",
    "\n",
    "# elapsed_time = time.time() - st\n",
    "# print('Execution time:', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes torch.Size([4, 4, 2, 25, 2, 2]) and torch.Size([1, 2]) not aligned in mode-1 multiplication: 4 (mode 1) != 2 (dim 1 of matrix)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epoch):\n\u001b[1;32m---> 34\u001b[0m     train(epoch)\n\u001b[0;32m     36\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining for all \u001b[39m\u001b[39m{\u001b[39;00mn_epoch\u001b[39m}\u001b[39;00m\u001b[39m epochs completed in: \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m output \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[0;32m     19\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mNet3.forward\u001b[1;34m(self, x, map_type)\u001b[0m\n\u001b[0;32m     13\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(F\u001b[39m.\u001b[39mmax_pool2d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x), \u001b[39m2\u001b[39m))\n\u001b[0;32m     15\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreshaper(x, map_type)\n\u001b[1;32m---> 17\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtcl(x))\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     18\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrl(x)\n\u001b[0;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlog_softmax(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tltorch\\factorized_layers\\tensor_contraction_layers.py:75\u001b[0m, in \u001b[0;36mTCL.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     74\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Performs a forward pass\"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     x \u001b[39m=\u001b[39m tenalg\u001b[39m.\u001b[39;49mmulti_mode_dot(\n\u001b[0;32m     76\u001b[0m         x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfactors, modes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontraction_modes)\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorly\\backend\\__init__.py:206\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_backend_method\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    203\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A dynamically dispatched method\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[39m    Returns the queried method from the currently set backend\"\"\"\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[0;32m    207\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_THREAD_LOCAL_DATA\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbackend\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_backend), name\n\u001b[0;32m    208\u001b[0m     )(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorly\\tenalg\\core_tenalg\\n_mode_product.py:132\u001b[0m, in \u001b[0;36mmulti_mode_dot\u001b[1;34m(tensor, matrix_or_vec_list, modes, skip, transpose)\u001b[0m\n\u001b[0;32m    130\u001b[0m     res \u001b[39m=\u001b[39m mode_dot(res, T\u001b[39m.\u001b[39mconj(T\u001b[39m.\u001b[39mtranspose(matrix_or_vec)), mode \u001b[39m-\u001b[39m decrement)\n\u001b[0;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     res \u001b[39m=\u001b[39m mode_dot(res, matrix_or_vec, mode \u001b[39m-\u001b[39;49m decrement)\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m T\u001b[39m.\u001b[39mndim(matrix_or_vec) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    135\u001b[0m     decrement \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorly\\tenalg\\core_tenalg\\n_mode_product.py:42\u001b[0m, in \u001b[0;36mmode_dot\u001b[1;34m(tensor, matrix_or_vector, mode, transpose)\u001b[0m\n\u001b[0;32m     40\u001b[0m dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m transpose \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m matrix_or_vector\u001b[39m.\u001b[39mshape[dim] \u001b[39m!=\u001b[39m tensor\u001b[39m.\u001b[39mshape[mode]:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     43\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mmatrix_or_vector\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m not aligned in mode-\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m multiplication: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mshape[mode]\u001b[39m}\u001b[39;00m\u001b[39m (mode \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m) != \u001b[39m\u001b[39m{\u001b[39;00mmatrix_or_vector\u001b[39m.\u001b[39mshape[dim]\u001b[39m}\u001b[39;00m\u001b[39m (dim 1 of matrix)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m     )\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n\u001b[0;32m     48\u001b[0m     matrix_or_vector \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mconj(T\u001b[39m.\u001b[39mtranspose(matrix_or_vector))\n",
      "\u001b[1;31mValueError\u001b[0m: shapes torch.Size([4, 4, 2, 25, 2, 2]) and torch.Size([1, 2]) not aligned in mode-1 multiplication: 4 (mode 1) != 2 (dim 1 of matrix)"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "n_epoch = 3\n",
    "model = Net3(device='cuda').to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_1_Train = []\n",
    "loss_1_Test = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss))\n",
    "    \n",
    "    avg_loss = total_loss / len(trainloader)\n",
    "    loss_1_Train.append(avg_loss)\n",
    "\n",
    "print(\"start train\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train(epoch)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training for all {n_epoch} epochs completed in: {end_time - start_time} seconds\")\n",
    "\n",
    "print(\"end train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "INDICES element is out of DATA bounds, id=2 axis_dim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m r1 \u001b[39m=\u001b[39m MyReshape(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m r2 \u001b[39m=\u001b[39m MyReshape2(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m t1 \u001b[39m=\u001b[39m r1(t,map_type\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# t2 = r2(t)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\Desktop\\reshape9\\reshape\\reshape.py:12\u001b[0m, in \u001b[0;36mMyReshape.__call__\u001b[1;34m(self, x, map_type)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, map_type\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m external_reshape(x, map_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\Desktop\\reshape9\\functional\\chunk_reshape.py:29\u001b[0m, in \u001b[0;36mexternal_reshape\u001b[1;34m(x, map_type, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[0;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m---> 29\u001b[0m         chunk \u001b[39m=\u001b[39m tensor_reshape(\n\u001b[0;32m     30\u001b[0m             x, [indices_list[\u001b[39m0\u001b[39;49m][i], indices_list[\u001b[39m1\u001b[39;49m][j], indices_list[\u001b[39m2\u001b[39;49m][k]])\n\u001b[0;32m     32\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     33\u001b[0m             memory \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\Mohammad Badzohreh\\Desktop\\reshape9\\functional\\chunk_reshape.py:21\u001b[0m, in \u001b[0;36mexternal_reshape.<locals>.tensor_reshape\u001b[1;34m(x, indices)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtensor_reshape\u001b[39m(x, indices):\n\u001b[0;32m     19\u001b[0m     chunk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mindex_select(\n\u001b[0;32m     20\u001b[0m         torch\u001b[39m.\u001b[39mindex_select(\n\u001b[1;32m---> 21\u001b[0m             torch\u001b[39m.\u001b[39;49mindex_select(x, \u001b[39m1\u001b[39;49m, indices[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)),\n\u001b[0;32m     22\u001b[0m             \u001b[39m2\u001b[39m, indices[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)),\n\u001b[0;32m     23\u001b[0m         \u001b[39m3\u001b[39m, indices[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m chunk\n",
      "\u001b[1;31mRuntimeError\u001b[0m: INDICES element is out of DATA bounds, id=2 axis_dim=2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "\n",
    "from reshape.reshape import MyReshape\n",
    "from reshape.reshape import MyReshape2\n",
    "\n",
    "\n",
    "r1 = MyReshape('cpu')\n",
    "r2 = MyReshape2('cpu')\n",
    "\n",
    "t1 = r1(t,map_type=1)\n",
    "# t2 = r2(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
